<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Tinghuai Wang</title>

  <meta name="author" content="Tinghuai Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Tinghuai Wang</name>
              </p>
              <p>I am a research manager in <a href="https://www.huawei.com/en/">Huawei Helsinki Research Center</a>, where I have been leading the research in computer vision and machine learning. My recent research interests focus on multimodal foundation models, reinforcement learning, and remote sensing.
              </p>
              <p>
                I received my PhD from the <a href="https://www.surrey.ac.uk/">University of Surrey</a> and MSc from <a href="https://www.kth.se/en">KTH</a> and <a href="https://www.rwth-aachen.de/">RWTH Aachen</a> in machine learning and computer vision. I have more than 10 years experience in research and innovation roles at various industry research labs (Huawei Helsinki Research Center, Nokia, HP Labs, Sony Research Labs). I have published 40 peer-reviewed international journals and conference publications, including top venues ICML, AAAI, IJCAI, BMVC, TVCG, TGRS, TMM, CVIU. My publications have won two IEEE best paper awards (MESH 2009, ICME 2015). I also (co-)invented 84 granted/pending patents filed in US and EU, with more than two dozens of technology transfers to influential products. I have been serving as programme committee member for top AI venues such as AAAI, IJCAI, and area chair of ICIP 2018, CVMP 2013-2016 and SIGRAPH/NPAR 2012-2016. He was awarded as distinguished PC member of IJCAI 2018.
              </p>
              <p style="text-align:center">
                <a href="mailto:tinghuai.wang@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.co.uk/citations?user=ZNhNwgsAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://patents.google.com/?inventor=tinghuai+wang&type=PATENT&num=100&sort=new&dups=language">Google Patents</a>&nbsp/&nbsp
                <a href="https://github.com/thwanguk/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm generally interested in computer vision/graphics, machine learning, and reinforcement learning.

                Representative papers and patents are listed as follows. Full list of publications can be found in my <a href="https://scholar.google.co.uk/citations?user=ZNhNwgsAAAAJ&hl=en">Google Scholar</a> page.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                          <img src="images/icml24.png" alt="ICML24" width="160" style="border-style: none">
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                          <a href="https://openreview.net/pdf?id=b6AwZauZPV">
                          <papertitle>Probabilistic Subgoal Representations for Hierarchical Reinforcement Learning</papertitle>
                          </a>
                          <br>
                          Vivienne Huiling Wang*,
                          <strong>Tinghuai Wang</strong>*,
                          Wenyan Yang,
                          Joni-Kristian Kämäräinen,
                          Joni Pajarinen
                          <br>
                          <em> The Forty-first International Conference on Machine Learning (ICML)</em>, 2024
                          <br>
                          <p></p>
                          <p>We propose a new Gaussian processes (GPs) based method for learning probabilistic subgoal representations in Hierarchical Reinforcement Learning (HRL).</p>
            </td>
            </tr>

        <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
                      <img src="images/agile.png" alt="Arxiv" width="160" style="border-style: none">
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://ojs.aaai.org/index.php/AAAI/article/view/26213/25985">
                      <papertitle> State-Conditioned Adversarial Subgoal Generation</papertitle>
                      </a>
                      <br>
                      Vivienne Huiling Wang,
                      Joni Pajarinen,
                      <strong>Tinghuai Wang</strong>,
                      Joni-Kristian Kämäräinen
                      <br>
                      <em> Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI)</em>, 2023
                      <br>
                      <a href="https://arxiv.org/pdf/2201.09635.pdf">pdf</a>
                      <p></p>
                      <p>We propose a novel adversarially guided subgoal generation framework for goal-conditioned HRL to mitigate the issue of non-stationarity in off-policy training.</p>
        </td>
        </tr>

        <tr>
<td style="padding:20px;width:25%;vertical-align:middle">
  <img src="images/GNSS-PDR22.jpg" alt="TIM22" width="160" style="border-style: none">
</td>
<td style="padding:20px;width:75%;vertical-align:middle">
  <a href="https://ieeexplore.ieee.org/document/9810479">
  <papertitle>“Smartphone PDR/GNSS Integration via Factor Graph Optimization
for Pedestrian Navigation”</papertitle>
  </a>
<br> Changhui Jiang, Yuwei Chen, hen Chen, Jianxin Jia, Haibin Sun, <strong>Tinghuai Wang</strong>, Juha Hyyppä <br>
  <em>IEEE Transactions on Instrumentation and Measurement</em>, 2022
  <br>
  <a href="https://ieeexplore.ieee.org/document/9810479">pdf</a>
  <p></p>
  <p> We propose two novel factor graph optimization (FGO)-based models to improve smartphone positioning accuracy by integrating pedestrian dead reckoning (PDR) with GNSS data. The first model combines position data from both PDR and GNSS, while the second tackles heading angle errors and smartphone misalignment by integrating PDR step length with GNSS. </p>
</td>
</tr>

<tr>
<td style="padding:20px;width:25%;vertical-align:middle">
<img src="images/TGRS21.png" alt="TGRS21" width="160" style="border-style: none">
</td>
<td style="padding:20px;width:75%;vertical-align:middle">
<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9497323">
<papertitle>“Tradeoffs in the Spatial and Spectral Resolution of Airborne Hyperspectral Imaging Systems: A Crop Identification Case Study”</papertitle>
</a>
<br> Jianxin Jia, Jinsong Chen, Xiaorou Zheng, Yueming Wang, Shanxin Guo, Haibin Sun, Changhui Jiang, Mika Karjalainen, Kirsi Karila, Zhiyong Duan, <strong>Tinghuai Wang</strong>, Chong Xu, Juha Hyyppä, Yuwei Chen <br>
<em>IEEE Transactions on Instrumentation and Measurement</em>, 2022
<br>
<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9497323">pdf</a>
<p></p>
<p>
We investigate the tradeoffs between signal-to-noise ratio (SNR), spatial resolution, and spectral resolution in hyperspectral imaging for crop identification, addressing gaps in existing research. Results show that overall accuracy decreases with lower SNR and coarser spectral resolution but improves with lower spatial resolution. This study bridges the gap between hyperspectral sensor design and practical crop identification. </p>
</td>
</tr>

                    <tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/isvc20.png" alt="ISVC20" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-64556-4_55">
              <papertitle>Hyperspectral Image Classification via Pyramid Graph Reasoning</papertitle>
              </a>
              <br>
              <strong>Tinghuai Wang</strong>,
              Guangming Wang,
              Kuan Eeik Tan,
              Donghui Tan
              <br>
              <em>ISVC</em>, 2020
              <br>
              <a href="https://link.springer.com/chapter/10.1007/978-3-030-64556-4_55">pdf</a>
              <p></p>
              <p> We design an architecture to encode the multiple spectral contextual information in the form of spectral pyramid of multiple embedding spaces. In each spectral embedding space, we propose graph attention mechanism to explicitly perform interpretable reasoning in the spatial domain based on the connection in spectral feature space.</p>
</td>
</tr>


          <tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/icann19.png" alt="ICANN19" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1906.04505.pdf">
              <papertitle>Simultaneously Learning Architectures and Features of Deep Neural Networks</papertitle>
              </a>
              <br>
              <strong>Tinghuai Wang</strong>,
              Lixin Fan,
              Huiling Wang
              <br>
              <em>ICANN</em>, 2019
              <br>
              <a href="https://arxiv.org/pdf/1906.04505.pdf">pdf</a>
              <p></p>
              <p> We propose a novel pruning loss to explicitly enforces the optimizer to focus on promising candidate filters while suppressing contributions of less relevant ones. In the meanwhile, we further propose to enforce the diversities between filters and this diversity-based regularization term improves the trade-off between model sizes and accuracies. <strong>Nokia</strong> proposal to ISO/IEC DIS 15938-17
Information technology — Multimedia content description interface — Part 17: Compression of neural networks for multimedia content description and analysis </p>
</td>
</tr>

<tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/iccvw19.png" alt="ICCVW19" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/NeurArch/Zhu_Cross-Granularity_Attention_Network_for_Semantic_Segmentation_ICCVW_2019_paper.pdf">
              <papertitle>Cross-Granularity Attention Network for Semantic Segmentation</papertitle>
              </a>
              <br>
              Lingyu Zhu*,
              <strong>Tinghuai Wang*</strong>,
              Emre Aksu,
              Joni-Kristian Kämäräinen
              <br>
              <em>ICCVW</em>, 2019
              <br>
              <a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/NeurArch/Zhu_Cross-Granularity_Attention_Network_for_Semantic_Segmentation_ICCVW_2019_paper.pdf">pdf</a>
              <p></p>
              <p> We propose a categorical attention mechanism to propagate consistent category-oriented information across multi-granularity contextual interpretations to close the semantic gap residing in CNN feature hierarchy; a cross-granularity contour enhancement mechanism is also proposed to propagate rich boundary cues from early layers to deep layers. These novel mechanisms boost the essentials in segmentation, i.e., region-wise semantic coherence and accurate object contour localization. </p>
</td>
</tr>


<tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/icme19.png" alt="ICME19" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://webpages.tuni.fi/vision/public_data/publications/icme2019_portrait_segmentation.pdf">
              <papertitle>Portrait Instance Segmentation for Mobile Devices</papertitle>
              </a>
              <br>
              Lingyu Zhu*,
              <strong>Tinghuai Wang*</strong>,
              Emre Aksu,
              Joni-Kristian Kämäräinen
              <br>
              <em>ICME</em>, 2019
              <br>
              <a href="https://webpages.tuni.fi/vision/public_data/publications/icme2019_portrait_segmentation.pdf">pdf</a>
              <p></p>
              <p> We propose a novel and efficient non-parametric affinity model to achieve efficient instance segmentation on mobile devices. We also present a portrait image dataset with instance level annotations dedicated to evaluating portrait instance segmentation algorithms. </p>
</td>
</tr>

<tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/segmentation.png" alt="Mobile Segmentation" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://patents.google.com/patent/US10872275B2/">
              <papertitle>Semantic segmentation based on a hierarchy of neural networks</papertitle>
              </a>
              <br>
              <strong>Tinghuai Wang</strong>
              <br>
              <em>US10872275B2</em>, 2019
              <br>
              <a href="images/icassp16.png">pdf</a>
              <p>Method for Nokia 8 Portrait Segmentation. </p>
</td>
</tr>



<tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ijcai17.png" alt="IJCAI17" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.ijcai.org/Proceedings/2017/0634.pdf">
              <papertitle>Cross-Granularity Graph Inference for Semantic Video Object Segmentation</papertitle>
              </a>
              <br>
              Huiling Wang,
              <strong>Tinghuai Wang</strong>,
              Ke Chen,
              Joni-Kristian Kämäräinen
              <br>
              <em>IJCAI</em>, 2017
              <br>
              <a href="https://www.ijcai.org/Proceedings/2017/0634.pdf">pdf</a>
              /
              <a href="https://www.youtube.com/watch?v=0QwewAUcGLI&feature=emb_logo">video</a>
              <p></p>
              <p>We address semantic video object segmentation
via a novel cross-granularity hierarchical graphical
model to integrate tracklet and object proposal reasoning with superpixel labeling.</p>
</td>
</tr>


<tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/npar17.png" alt="NPAR17" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://orca.cf.ac.uk/103270/1/portrait.pdf">
              <papertitle>Benchmarking Non-Photorealistic Rendering of Portraits</papertitle>
              </a>
<br> Paul L. Rosin, David Mould, Itamar Berger, John P. Collomosse, Yu-Kun Lai, Chuan Li, Hua Li, Ariel Shamir, Michael Wand, <strong>Tinghuai Wang</strong>, Holger Winnemöller <br>
              <em>NPAR</em>, 2017
              <br>
              <a href="https://orca.cf.ac.uk/103270/1/portrait.pdf">pdf</a>
              <p></p>
              <p>We present a set of images for helping NPR practitioners evaluate their image-based portrait stylisation algorithms. </p>
</td>
</tr>

<tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/vidobjdet.png" alt="video object detection" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://patents.google.com/patent/US10778988B2">
              <papertitle>Method, an apparatus and a computer program product for object detection</papertitle>
              </a>
              <br>
              <strong>Tinghuai Wang</strong>,
              <br>
              <em>US10778988B2</em>, 2017
              <br>
              <a href="https://patents.google.com/patent/US10778988B2">pdf</a>

              <p></p>
              <p>Video object detection method for Nokia OZO camera. </p>
            </td>
</tr>



<tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cviu16.png" alt="CVIU16" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S1077314215002507">
              <papertitle>Primary Object Discovery and Segmentation in Videos via Graph-Based Transductive Inference</papertitle>
              </a>
              <br>
              Huiling Wang,
              <strong>Tinghuai Wang</strong>
              <br>
              <em>CVIU</em>, 2016
              <br>
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S1077314215002507">pdf</a>
              <p></p>
              <p>We present a novel algorithm that detects recurring primary object and learns cohort object proposals over space-time in video. Our core contribution is a graph transduction process that exploits both appearance cues learned from rudimentary detections of object-like regions, and the intrinsic structures within video data.</p>
</td>
</tr>


<tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/icassp16.png" alt="ICASSP16" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="data/icassp16.pdf">
              <papertitle>Boosting Objectness: Semi-Supervised Learning for Object Detection and Segmentation in Multi-View Images</papertitle>
              </a>
              <br>
              Huiling Wang,
              <strong>Tinghuai Wang</strong>
              <br>
              <em>ICASSP</em>, 2016
              <br>
              <a href="images/icassp16.png">pdf</a>
              /
              <a href="https://youtu.be/TVuasWgguik">video #1</a>
              /
              <a href="https://youtu.be/mCzclDuRN_4">video #1</a>
              <p></p>
              <p>This paper presents a method to detect and segment recurring object from multi-view images. By harnessing a top-down explicit notion of object, our method overcomes the limitations of previous bottom-up methods that often mis-segment an object and de- livers high quality segmentation.</p>
</td>
</tr>


<tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/vrpositioning.png" alt="VR Cam Pos" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://patents.google.com/patent/GB2557212A">
              <papertitle>Methods and apparatuses for determining positions of multi-directional image capture apparatuses</papertitle>
              </a>
<br> <strong>Tinghuai Wang</strong>, Yu You, Lixin Fan, Kimmo Roimela <br>
              <em>GB2557212A</em>, 2016
              <br>
              <a href="https://patents.google.com/patent/GB2557212A">pdf</a>
              <p>Method for Nokia OZO camera positioning. </p>
</td>
</tr>

<tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/vrrendering.png" alt="VR Rendering" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://patents.google.com/patent/US10701433B2">
              <papertitle>Rendering of user-defined message having 3D motion information</papertitle>
              </a>
              <br>
              Yu You,
              Lixin Fan,
              <strong>Tinghuai Wang</strong>
              <br>
              <em>US10701433B2</em>, 2016
              <br>
              <a href="https://patents.google.com/patent/US10701433B2">pdf</a>
              <p>Method for Nokia OZO VR content rendering. </p>
</td>
</tr>

<tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/vrrendering2.png" alt="VR Rendering" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://patents.google.com/patent/US10762722B2">
              <papertitle>Apparatus for sharing objects of interest and associated methods
</papertitle>
              </a>
              <br>
              <strong>Tinghuai Wang</strong>,
              Lixin Fan,
              Yu You

              <br>
              <em>US10701433B2</em>, 2016
              <br>
              <a href="https://patents.google.com/patent/US10762722B2">pdf</a>
              <p>Method for Nokia OZO VR content view synthesis. </p>
</td>
</tr>

                    <tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/nc15.jpg" alt="NC15" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S092523121500836X">
              <papertitle>A Weakly Supervised Geodesic Level Set Framework for Interactive Image Segmentation</papertitle>
              </a>
              <br>
              <strong>Tinghuai Wang</strong>,
              Huiling Wang,
              Lixin Fan
              <br>
              <em>Neurocomputing</em>, 2015
              <br>
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S092523121500836X">pdf</a>
              <p></p>
              <p> We combine geodesic distance information with the flexibility of level set methods in energy minimization, leveraging the complementary strengths of each to promote accurate boundary placement and strong region connectivity while requiring less user interaction.  </p>
</td>
</tr>


          <tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/icme15.png" alt="ICME15" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="data/icme15.pdf">
              <papertitle>Robust Interactive Image Segmentation with Weak Supervision for Mobile Touch Screen Devices</papertitle>
              </a>
              <br>
              <strong>Tinghuai Wang</strong>,
              Huiling Wang,
              Lixin Fan
              <br>
              <em>ICME</em>, 2015
              <br>
              <a href="data/icme15.pdf">pdf</a>
              /
              <a href="https://www.youtube.com/watch?v=0QwewAUcGLI&feature=emb_logo">video</a>
              <p></p>
              <p>We present a a robust and efficient approach for segmenting images with less and intuitive user interaction, particularly targeted for mobile touch screen devices. </p>
</td>
</tr>


<tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cviu14.png" alt="CVIU14" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://personal.ee.surrey.ac.uk/Personal/J.Collomosse/pubs/Wang-CVIU-2014.pdf">
              <papertitle>TouchCut: Fast Image and Video Segmentation using Single-Touch Interaction</papertitle>
              </a>
              <br>
              <strong>Tinghuai Wang</strong>,
              Bo Han,
              John Collomosse
              <br>
              <em>CVIU</em>, 2014
              <br>
              <a href="http://personal.ee.surrey.ac.uk/Personal/J.Collomosse/pubs/Wang-CVIU-2014.pdf">pdf</a>
              /
              <a href="https://www.youtube.com/watch?v=Qvw5zYGqi5I">video</a>
              <p></p>
              <p>We present TouchCut; a robust and efficient algorithm for segmenting image and video sequences with minimal user interaction i.e., only a single finger touch to identify the object of interest in the image or first frame of video. This approach to visual object cut-out provides a practical solution for image and video segmentation on compact touch screen devices, facilitating spatially localized media manipulation.</p>
</td>
</tr>


<tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/icpr14.png" alt="ICPR14" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://personal.ee.surrey.ac.uk/Personal/J.Collomosse/pubs/Wang-ICPR-2014.pdf">
              <papertitle>Wide Baseline Multi-View Video Matting using a Hybrid Markov Random Field</papertitle>
              </a>
              <br>
              <strong>Tinghuai Wang</strong>,
              John Collomosse,
              Adrian Hilton
              <br>
              <em>ICPR</em>, 2014
              <br>
              <a href="http://personal.ee.surrey.ac.uk/Personal/J.Collomosse/pubs/Wang-ICPR-2014.pdf">pdf</a>
              <p></p>
              <p>We present a novel multi-view video matting
method suitable for incorporation into a 4DPC pipeline. The
key contributions of this method are 1) the propagation of
appearance and spatial information across views using superpixel matching and a novel MRF that solves the mattes
simultaneously across all views, 2) the temporal propagation
of appearance and spatial information forward in time. </p>
</td>
</tr>


<tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/segmentation2.png" alt="interactive seg" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://patents.google.com/patent/US9495755B2/">
              <papertitle>Apparatus, a method and a computer program for image processing</papertitle>
              </a>
              <br>
              <strong>Tinghuai Wang</strong>,
              <br>
              <em>US9495755B2</em>, 2013
              <br>
              <a href="https://patents.google.com/patent/US9495755B2/">pdf</a>

              <p></p>
              <p>Interactive segmentation method for Nokia Lumia Phone.</p>
            </td>
</tr>


<tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/tvcg12.png" alt="TVCG13" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://hal.inria.fr/hal-00781502/document">
              <papertitle>State of the'Art': A Taxonomy of Artistic Stylization Techniques for Images and Video</papertitle>
              </a>
              <br>
              Jan Eric Kyprianidis,
              John Collomosse,
              <strong>Tinghuai Wang</strong>,
              <a href="https://scholar.google.co.uk/citations?user=r6Y4nacAAAAJ&hl=en">Tobias Isenberg</a>
              <br>
              <em>TVCG</em>, 2013
              <br>
              <a href="https://hal.inria.fr/hal-00781502/document">pdf</a>

              <p></p>
              <p>We survey the field of non-photorealistic rendering (NPR), focusing on techniques for transforming 2D input
(images and video) into artistically stylized renderings.</p>
            </td>
</tr>


          <tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/bmvc13.png" alt="BMVC13" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://personal.ee.surrey.ac.uk/Personal/J.Collomosse/pubs/Wang-BMVC-2013.pdf">
              <papertitle>Learnable Stroke Models for Example-based Portrait Painting</papertitle>
              </a>
              <br>
              <strong>Tinghuai Wang,</strong>,
              John Collomosse,
              Andrew Hunter,
              Darryl Greig
              <br>
              <em>BMVC</em>, 2013
              <br>
              <a href="http://personal.ee.surrey.ac.uk/Personal/J.Collomosse/pubs/Wang-BMVC-2013.pdf">pdf</a>
              /
              <a href="http://sdrv.ms/11emjDu">poster</a>
              <p></p>
              <p>We present the first machine learning model which is capable of learning artistic style for portraits by analyzing training
data from a human artist. Given a training pair — a source image and painting of that image — a non-parametric model of style is learned by observing the geometry and tone of brush strokes local to image features.</p>
</td>
</tr>


<tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/icmr13.png" alt="ICMR13" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://personal.ee.surrey.ac.uk/Personal/J.Collomosse/pubs/Hu-ICMR-2013.pdf">
              <papertitle>Markov Random Fields for Sketch based Video Retrieval</papertitle>
              </a>
              <br>
              Rui Hu,
              Stuart James,
              <strong>Tinghuai Wang</strong>,
              John Collomosse
              <br>
              <em>ICMR</em>, 2013
              <br>
              <a href="http://personal.ee.surrey.ac.uk/Personal/J.Collomosse/pubs/Hu-ICMR-2013.pdf">pdf</a>
              <p></p>
              <p>We describe a new system for searching video databases using free-hand sketched queries. Our query sketches depict
both object appearance and motion, and are annotated with
keywords that indicate the semantic category of each object.
We parse space-time volumes from video to form graph representation, which we match to sketches under a Markov
Random Field (MRF) optimization.  </p>
</td>
</tr>





    <tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/tmm12.png" alt="TMM12" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://personal.ee.surrey.ac.uk/Personal/J.Collomosse/pubs/Wang-TMM-2012.pdf">
              <papertitle>Progressive Motion Diffusion of Labeling Priors for Coherent Video Segmentation</papertitle>
              </a>
              <br>
              <strong>Tinghuai Wang</strong>,
              John Collomosse
              <br>
              <em>TMM</em>, 2012
              <br>
              <a href="http://personal.ee.surrey.ac.uk/Personal/J.Collomosse/pubs/Wang-TMM-2012.pdf">pdf</a>
              /
              <a href="https://youtu.be/8CThGf9iZZk">video</a>
              <p></p>
              <p>We present a novel algorithm for video segmentation and our core contribution is a multi-frame probabilistic motion diffusion model to incorporate labelling priors from previous frames to influence the segmentation in new frame.</p>
</td>
</tr>

          <tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cag11.png" alt="CAG11" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://personal.ee.surrey.ac.uk/Personal/J.Collomosse/pubs/Wang-CAG-2010.pdf">
              <papertitle>Stylized Ambient Displays of Digital Media Collections</papertitle>
              </a>
<br> <strong>Tinghuai Wang</strong>, John Collomosse, David Slatter, Phil Cheatle, Darryl Greig <br>
              <em>Computer and Graphics</em>, 2011
              <br>
              <a href="http://personal.ee.surrey.ac.uk/Personal/J.Collomosse/pubs/Wang-CAG-2010.pdf">pdf</a>
              /
              <a href="http://sdrv.ms/11emjDu">poster</a>
              <p></p>
              <p>We present a system to breathe life into home digital media collections, drawing upon artistic stylization to create a ‘‘Digital Ambient Display’’ that automatically selects, stylizes and transitions between digital contents in a semantically meaningful sequence. </p>
</td>
</tr>


<tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/icip11.png" alt="ICIP11" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://personal.ee.surrey.ac.uk/Personal/J.Collomosse/pubs/Hu-ICIP-2011.pdf">
              <papertitle>A Bag-of-Regions Approach to Sketch-based Image Retrieval </papertitle>
              </a>
<br> Rui Hu, <strong>Tinghuai Wang</strong>, John Collomosse <br>
              <em>ICIP</em>, 2011
              <br>
              <a href="http://personal.ee.surrey.ac.uk/Personal/J.Collomosse/pubs/Hu-ICIP-2011.pdf">pdf</a>
              <p></p>
              <p>We present a sketch based image retrieval
system built on a bag of regions which encodes the complete information of salient shapes at various level of details
in the form of enclosed contours of regions presenting a coherent visual appearance. </p>
</td>
</tr>


<tr>
<td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cvmp09.png" alt="CVMP09" width="160" style="border-style: none">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://personal.ee.surrey.ac.uk/Personal/J.Collomosse/pubs/Wang-CVMP-2009.pdf">
              <papertitle>An Evolutionary Approach to Automatic Video Editing</papertitle>
              </a>
              <br> <strong>Tinghuai Wang</strong>, Andrew Mansfield, John Collomosse, Rui Hu <br>
              <em>CVMP</em>, 2009
              <br>
              <a href="http://personal.ee.surrey.ac.uk/Personal/J.Collomosse/pubs/Wang-CVMP-2009.pdf">pdf</a>
              <p></p>
              <p>We interpret the sequence of editting operations
applied to footage as a ‘program’ comprising cutting,
panning and zooming constructs. We develop a Genetic
Programming (GP) framework for representing and evolving
such programs. Under this framework, the search for an
aesthetically pleasing video edit becomes a search for the
optimal genetic program. Our aesthetic criterion promotes
the inclusion of people in shots, whilst penalising rapid shot
changes or shot changes in the presence of camera motion. </p>
</td>
</tr>

        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Recent Service</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>

            <td width="75%" valign="center">
              <a > Program Committee, AAAI 2017-2025</a>
              <br><br>
              <a > Program Committee, IJCAI 2017-2019</a>
              <a > Area Chair, CVMP 2013-2016</a>
              <a > Area Chair, SIGRAPH/NPAR 2012-2016</a>
              <br><br>
              <a href="https://2018.ieeeicip.org/">Area Chair, ICIP 2018</a>
            </td>
          </tr>
        </tbody></table>
</body>

</html>
